This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-14T01:45:36.541Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
scripts/
  setup.sh
src/
  middleware/
    composable.integration.test.ts
    composable.test.ts
    composable.ts
  routes/
    face-recognition.integration.test.ts
    face-recognition.ts
    health.integration.test.ts
    health.ts
  types/
    face-recognition.ts
  use-cases/
    face-recognition/
      index.test.ts
      index.ts
    health/
      index.test.ts
      index.ts
  app.ts
  index.ts
.eslintrc.json
.gitignore
.prettierrc
jest.config.js
package.json
README.md
tsconfig.json
vitest.config.ts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="scripts/setup.sh">
#!/bin/bash
# Create necessary directories
mkdir -p models storage/faces storage/gallery
# Download face-api.js models
MODELS_URL="https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights"
MODELS=(
  "ssd_mobilenetv1_model-weights_manifest.json"
  "ssd_mobilenetv1_model-shard1"
  "ssd_mobilenetv1_model-shard2"
  "face_landmark_68_model-weights_manifest.json"
  "face_landmark_68_model-shard1"
  "face_recognition_model-weights_manifest.json"
  "face_recognition_model-shard1"
  "face_recognition_model-shard2"
)
echo "Downloading face-api.js models..."
cd models
for model in "${MODELS[@]}"; do
  if [ ! -f "$model" ]; then
    echo "Downloading $model..."
    curl -L -O "$MODELS_URL/$model"
  else
    echo "$model already exists, skipping..."
  fi
done
cd ..
# Install dependencies
echo "Installing dependencies..."
npm install
# Create .env file if it doesn't exist
if [ ! -f .env ]; then
  echo "Creating .env file..."
  cp .env.sample .env
fi
# Make storage directories writable
chmod -R 755 storage
echo "Setup complete! ðŸŽ‰"
echo "Now you can:"
echo "1. Add face images to storage/faces/"
echo "2. Create albums in storage/gallery/"
echo "3. Add pictures to your albums in storage/gallery/<album-name>/"
echo "4. Start the API with: npm run dev"
</file>

<file path="src/middleware/composable.integration.test.ts">
import express, { Request, Response } from 'express';
import request from 'supertest';
import { success, failure } from 'composable-functions';
import { withComposable } from './composable';
describe('Composable Middleware Integration', () => {
  const app = express();
  app.get(
    '/success',
    withComposable((_req: Request, _res: Response) =>
      Promise.resolve(success({ message: 'Success' })),
    ),
  );
  app.get(
    '/failure',
    withComposable((_req: Request, _res: Response) =>
      Promise.resolve(failure([new Error('Test error')])),
    ),
  );
  app.get(
    '/invalid',
    withComposable((_req: Request, _res: Response) =>
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      Promise.resolve({ invalid: 'format' } as any),
    ),
  );
  app.get(
    '/error',
    withComposable((_req: Request, _res: Response) => {
      throw new Error('Unexpected error');
    }),
  );
  it('should handle successful responses', async () => {
    const response = await request(app).get('/success');
    expect(response.status).toBe(200);
    expect(response.body).toEqual({
      success: true,
      data: { message: 'Success' },
      errors: [],
    });
  });
  it('should handle failure responses with 500 status', async () => {
    const response = await request(app).get('/failure');
    expect(response.status).toBe(500);
    expect(response.body).toEqual({
      success: false,
      errors: [{ message: 'Test error' }],
    });
  });
  it('should handle invalid result format', async () => {
    const response = await request(app).get('/invalid');
    expect(response.status).toBe(500);
    expect(response.body).toEqual({
      success: false,
      errors: [{ message: 'Invalid composable result format' }],
    });
  });
  it('should handle thrown errors', async () => {
    const response = await request(app).get('/error');
    expect(response.status).toBe(500);
    expect(response.body).toEqual({
      message: 'Unexpected error',
    });
  });
});
</file>

<file path="src/middleware/composable.test.ts">
import { describe, it, expect, vi } from 'vitest';
import { Request, Response } from 'express';
import { withComposable } from './composable';
import { success, failure } from 'composable-functions';
describe('withComposable', () => {
  const mockRequest = {} as Request;
  const mockResponse = {
    status: vi.fn().mockReturnThis(),
    json: vi.fn(),
  } as unknown as Response;
  const mockNext = vi.fn() as unknown as (err?: unknown) => void;
  beforeEach(() => {
    vi.clearAllMocks();
  });
  it('should handle successful results', async () => {
    const mockData = { foo: 'bar' };
    const handler = vi.fn().mockResolvedValue(success(mockData));
    const middleware = withComposable(handler);
    await middleware(mockRequest, mockResponse, mockNext);
    expect(mockResponse.json).toHaveBeenCalledWith({
      success: true,
      data: mockData,
      errors: [],
    });
  });
  it('should handle failure results with 500 status', async () => {
    const mockError = new Error('Test error');
    const handler = vi.fn().mockResolvedValue(failure([mockError]));
    const middleware = withComposable(handler);
    await middleware(mockRequest, mockResponse, mockNext);
    expect(mockResponse.status).toHaveBeenCalledWith(500);
    expect(mockResponse.json).toHaveBeenCalledWith({
      success: false,
      errors: [{ message: 'Test error' }],
    });
  });
  it('should handle invalid result format', async () => {
    const handler = vi.fn().mockResolvedValue({ invalid: 'format' });
    const middleware = withComposable(handler);
    await middleware(mockRequest, mockResponse, mockNext);
    expect(mockResponse.status).toHaveBeenCalledWith(500);
    expect(mockResponse.json).toHaveBeenCalledWith({
      success: false,
      errors: [{ message: 'Invalid composable result format' }],
    });
  });
  it('should handle thrown errors', async () => {
    const mockError = new Error('Test error');
    const handler = vi.fn().mockRejectedValue(mockError);
    const middleware = withComposable(handler);
    await middleware(mockRequest, mockResponse, mockNext);
    expect(mockResponse.status).toHaveBeenCalledWith(500);
    expect(mockResponse.json).toHaveBeenCalledWith({
      message: 'Test error',
    });
  });
});
</file>

<file path="src/middleware/composable.ts">
import { NextFunction, Request, Response } from 'express';
import type { Result } from 'composable-functions';
import { z } from 'zod';
export type ComposableRequestHandler<T = unknown> = (
  req: Request,
  res: Response,
) => Promise<Result<T>>;
export const ComposableResultSchema = z.discriminatedUnion('success', [
  z.object({
    success: z.literal(true),
    data: z.unknown(),
    errors: z.array(z.instanceof(Error)).optional(),
  }),
  z.object({
    success: z.literal(false),
    data: z.unknown().optional(),
    errors: z.array(z.instanceof(Error)),
  }),
]);
const serializeError = (error: Error): { message: string } => ({
  message: error.message,
});
export const withComposable = (handler: ComposableRequestHandler) => {
  return async (
    req: Request,
    res: Response,
    _next: NextFunction,
  ): Promise<void> => {
    try {
      const result = await handler(req, res);
      const validationResult = ComposableResultSchema.safeParse(result);
      if (!validationResult.success) {
        res.status(500).json({
          success: false,
          errors: [
            serializeError(new Error('Invalid composable result format')),
          ],
        });
        return;
      }
      if (!result.success) {
        res.status(500).json({
          ...result,
          errors: result.errors.map(serializeError),
        });
        return;
      }
      res.json({
        ...result,
        errors: result.errors?.map(serializeError) ?? [],
      });
    } catch (error) {
      if (error instanceof Error) {
        res.status(500).json(serializeError(error));
      } else {
        res.status(500).json({
          message: 'An unknown error occurred',
        });
      }
    }
  };
};
</file>

<file path="src/routes/face-recognition.integration.test.ts">
import request from 'supertest';
import app from '../app';
import fs from 'fs/promises';
import path from 'path';
describe('Face Recognition API', () => {
  const testFacePath = 'test-face.jpg';
  const testAlbumName = 'test-album';
  const testAlbumPath = path.join('storage', 'gallery', testAlbumName);
  const testFaceStoragePath = path.join('storage', 'faces', testFacePath);
  beforeAll(async () => {
    // Create test directories
    await fs.mkdir(path.join('storage', 'faces'), { recursive: true });
    await fs.mkdir(testAlbumPath, { recursive: true });
    // Copy test images (you'll need to provide these)
    // await fs.copyFile(
    //   path.join('test', 'fixtures', 'face.jpg'),
    //   testFaceStoragePath
    // )
    // await fs.copyFile(
    //   path.join('test', 'fixtures', 'gallery-1.jpg'),
    //   path.join(testAlbumPath, 'image1.jpg')
    // )
  });
  afterAll(async () => {
    // Clean up test files
    try {
      await fs.unlink(testFaceStoragePath);
      await fs.rm(testAlbumPath, { recursive: true });
    } catch (error) {
      // Ignore cleanup errors
    }
  });
  describe('POST /face-recognition/match', () => {
    it('should return 400 if request body is invalid', async () => {
      const response = await request(app)
        .post('/face-recognition/match')
        .send({});
      expect(response.status).toBe(400);
      expect(response.body).toHaveProperty('error');
    });
    // Uncomment when you have test images
    // it('should find matching faces in the album', async () => {
    //   const response = await request(app)
    //     .post('/face-recognition/match')
    //     .send({
    //       albumName: testAlbumName,
    //       facePath: testFacePath,
    //     })
    //   expect(response.status).toBe(200)
    //   expect(response.body).toHaveProperty('matches')
    //   expect(Array.isArray(response.body.matches)).toBe(true)
    //   // If there are matches, verify their structure
    //   if (response.body.matches.length > 0) {
    //     const match = response.body.matches[0]
    //     expect(match).toHaveProperty('imagePath')
    //     expect(match).toHaveProperty('similarity')
    //     expect(match).toHaveProperty('boundingBox')
    //     expect(match.similarity).toBeGreaterThan(0.6)
    //   }
    // })
  });
});
</file>

<file path="src/routes/face-recognition.ts">
import { Router } from 'express';
import { findMatches } from '../use-cases/face-recognition';
import { FaceMatchRequestSchema } from '../types/face-recognition';
const router = Router();
router.post('/match', async (req, res) => {
  try {
    const request = FaceMatchRequestSchema.parse(req.body);
    const result = await findMatches(request);
    if (!result.success) {
      return res
        .status(400)
        .json({ error: result.errors.map((e) => e.message).join(', ') });
    }
    res.json(result.data);
  } catch (error) {
    if (error instanceof Error) {
      res.status(400).json({ error: error.message });
    } else {
      res.status(500).json({ error: 'Internal server error' });
    }
  }
});
export default router;
</file>

<file path="src/routes/health.integration.test.ts">
import request from 'supertest';
import app from '../app';
describe('Health Check Endpoint', () => {
  it('should return a valid health check response', async () => {
    const response = await request(app).get('/health');
    expect(response.status).toBe(200);
    expect(response.body.success).toBe(true);
    expect(response.body.data.status).toBe('ok');
    expect(new Date(response.body.data.timestamp)).toBeInstanceOf(Date);
  });
});
</file>

<file path="src/routes/health.ts">
import { Router } from 'express';
import { getHealthCheck } from '../use-cases/health/index';
import { withComposable } from '../middleware/composable';
const router = Router();
router.get(
  '/',
  withComposable((_req, _res) => getHealthCheck()),
);
export default router;
</file>

<file path="src/types/face-recognition.ts">
import { z } from 'zod';
export const FaceMatchRequestSchema = z.object({
  albumName: z.string().min(1),
  facePath: z.string().min(1),
});
export type FaceMatchRequest = z.infer<typeof FaceMatchRequestSchema>;
export const FaceMatchResultSchema = z.object({
  imagePath: z.string(),
  similarity: z.number(),
  boundingBox: z.object({
    x: z.number(),
    y: z.number(),
    width: z.number(),
    height: z.number(),
  }),
});
export type FaceMatchResult = z.infer<typeof FaceMatchResultSchema>;
export const FaceMatchResponseSchema = z.object({
  matches: z.array(FaceMatchResultSchema),
});
export type FaceMatchResponse = z.infer<typeof FaceMatchResponseSchema>;
</file>

<file path="src/use-cases/face-recognition/index.test.ts">
import { describe, it, expect, vi, beforeEach } from 'vitest';
import { findMatches } from '.';
import * as faceapi from 'face-api.js';
import fs from 'fs/promises';
import { Dirent } from 'fs';
import { success } from 'composable-functions';
// Mock dependencies
vi.mock('face-api.js', () => ({
  env: {
    monkeyPatch: vi.fn(),
  },
  nets: {
    ssdMobilenetv1: {
      loadFromDisk: vi.fn(),
    },
    faceLandmark68Net: {
      loadFromDisk: vi.fn(),
    },
    faceRecognitionNet: {
      loadFromDisk: vi.fn(),
    },
  },
  detectSingleFace: vi.fn(),
  euclideanDistance: vi.fn(),
}));
// Mock canvas with all required exports
vi.mock('canvas', () => {
  const mockContext = {
    drawImage: vi.fn(),
  };
  const mockCanvas = {
    getContext: vi.fn(() => mockContext),
    width: 800,
    height: 600,
  };
  return {
    createCanvas: vi.fn(() => mockCanvas),
    loadImage: vi.fn(() => ({
      width: 800,
      height: 600,
    })),
    Canvas: class {
      getContext(): typeof mockContext {
        return mockContext;
      }
    },
    Image: class {},
    ImageData: class {},
  };
});
vi.mock('fs/promises');
describe('Face Recognition Use Case', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });
  it('should return empty matches when no faces are found', async () => {
    // Mock file system
    const mockDirents = [
      { name: 'image1.jpg', isFile: () => true } as Dirent,
      { name: 'image2.jpg', isFile: () => true } as Dirent,
    ];
    vi.mocked(fs.readdir).mockResolvedValue(mockDirents);
    // Mock face detection to return null (no face found)
    const mockDetectSingleFace = {
      withFaceLandmarks: vi.fn().mockReturnThis(),
      withFaceDescriptor: vi.fn().mockResolvedValue(null),
    };
    vi.mocked(faceapi.detectSingleFace).mockReturnValue(
      mockDetectSingleFace as unknown as ReturnType<
        typeof faceapi.detectSingleFace
      >,
    );
    const result = await findMatches({
      albumName: 'test-album',
      facePath: 'test-face.jpg',
    });
    expect(result).toEqual(success({ matches: [] }));
  });
  it('should return matches when faces are found', async () => {
    // Mock file system first
    vi.mocked(fs.readdir).mockResolvedValue([
      { name: 'image1.jpg', isFile: () => true } as Dirent,
    ]);
    // Mock face detection with successful matches
    const mockDetection = {
      descriptor: new Float32Array(128),
      detection: {
        box: {
          x: 0,
          y: 0,
          width: 100,
          height: 100,
        },
      },
      landmarks: {},
    };
    // Create a mock that always returns a successful detection
    const mockWithFaceDescriptor = vi.fn().mockResolvedValue(mockDetection);
    const mockWithFaceLandmarks = vi
      .fn()
      .mockReturnValue({ withFaceDescriptor: mockWithFaceDescriptor });
    const mockDetectSingleFace = { withFaceLandmarks: mockWithFaceLandmarks };
    // Mock detectSingleFace to always return the same mock
    vi.mocked(faceapi.detectSingleFace).mockImplementation(() => {
      console.log('detectSingleFace called');
      return mockDetectSingleFace as unknown as ReturnType<
        typeof faceapi.detectSingleFace
      >;
    });
    // Mock distance calculation to return a good match
    vi.mocked(faceapi.euclideanDistance).mockImplementation((desc1, desc2) => {
      console.log('euclideanDistance called with:', desc1, desc2);
      return 0.3; // 1 - 0.3 = 0.7 similarity
    });
    const result = await findMatches({
      albumName: 'test-album',
      facePath: 'test-face.jpg',
    });
    console.log('Test result:', JSON.stringify(result, null, 2));
    expect(result).toEqual(
      success({
        matches: [
          {
            imagePath: expect.stringContaining('image1.jpg'),
            similarity: 0.7,
            boundingBox: {
              x: 0,
              y: 0,
              width: 100,
              height: 100,
            },
          },
        ],
      }),
    );
    // Verify that the mocks were called correctly
    expect(faceapi.detectSingleFace).toHaveBeenCalledTimes(2); // Once for target face, once for gallery image
    expect(mockWithFaceLandmarks).toHaveBeenCalledTimes(2);
    expect(mockWithFaceDescriptor).toHaveBeenCalledTimes(2);
    expect(faceapi.euclideanDistance).toHaveBeenCalledTimes(1);
  });
});
</file>

<file path="src/use-cases/face-recognition/index.ts">
import * as faceapi from 'face-api.js';
import { createCanvas, loadImage, Canvas, Image, ImageData } from 'canvas';
import { composable } from 'composable-functions';
import { readdir } from 'fs/promises';
import { Dirent } from 'fs';
import path from 'path';
import { FaceMatchRequest } from '../../types/face-recognition';
// Monkey patch the faceapi canvas with type assertions for Node's canvas implementation
faceapi.env.monkeyPatch({
  Canvas: Canvas as unknown as typeof HTMLCanvasElement,
  Image: Image as unknown as typeof HTMLImageElement,
  ImageData: ImageData as unknown as typeof globalThis.ImageData,
});
// Load models on startup
let modelsLoaded = false;
const loadModels = async (): Promise<void> => {
  if (modelsLoaded) return;
  await faceapi.nets.ssdMobilenetv1.loadFromDisk('models');
  await faceapi.nets.faceLandmark68Net.loadFromDisk('models');
  await faceapi.nets.faceRecognitionNet.loadFromDisk('models');
  modelsLoaded = true;
};
const getFaceDescriptor = async (
  imagePath: string,
): Promise<faceapi.WithFaceDescriptor<
  faceapi.WithFaceLandmarks<{ detection: faceapi.FaceDetection }>
> | null> => {
  await loadModels();
  const img = await loadImage(imagePath);
  const canvas = createCanvas(img.width, img.height);
  const ctx = canvas.getContext('2d');
  ctx.drawImage(img, 0, 0);
  console.log(`Getting face descriptor for ${imagePath}`);
  const detection = await faceapi
    .detectSingleFace(canvas as unknown as HTMLCanvasElement)
    .withFaceLandmarks()
    .withFaceDescriptor();
  console.log(`Face detection result for ${imagePath}:`, detection);
  return detection || null;
};
export const findMatches = composable(async (request: FaceMatchRequest) => {
  const { albumName, facePath } = request;
  const faceImagePath = path.join('storage', 'faces', facePath);
  const galleryPath = path.join('storage', 'gallery', albumName);
  // Get face descriptor for the target face
  console.log('Getting target face descriptor...');
  const targetFace = await getFaceDescriptor(faceImagePath);
  if (!targetFace) {
    console.log('No face found in target image');
    return { matches: [] };
  }
  console.log('Target face descriptor:', targetFace.descriptor);
  // Get all images from the gallery
  const files = await readdir(galleryPath, { withFileTypes: true });
  console.log('Raw files from readdir:', files);
  const imageFiles = files.filter((file: Dirent) => {
    const isImage = /\.(jpg|jpeg|png)$/i.test(file.name);
    console.log(`File ${file.name} is image: ${isImage}`);
    return isImage;
  });
  console.log('Filtered image files:', imageFiles);
  // Process each gallery image
  const matches = [];
  for (const file of imageFiles) {
    const imagePath = path.join(galleryPath, file.name);
    console.log(`Processing gallery image: ${imagePath}`);
    try {
      const detection = await getFaceDescriptor(imagePath);
      if (!detection) {
        console.log(`No face found in gallery image: ${imagePath}`);
        continue;
      }
      console.log(`Found face in gallery image: ${imagePath}`);
      // Calculate similarity
      const distance = faceapi.euclideanDistance(
        targetFace.descriptor,
        detection.descriptor,
      );
      const similarity = 1 - distance;
      console.log(`Similarity for ${imagePath}: ${similarity}`);
      // Only include matches above threshold
      if (similarity > 0.6) {
        console.log(`Adding match: ${imagePath} (similarity: ${similarity})`);
        matches.push({
          imagePath: path.relative(process.cwd(), imagePath),
          similarity,
          boundingBox: {
            x: detection.detection.box.x,
            y: detection.detection.box.y,
            width: detection.detection.box.width,
            height: detection.detection.box.height,
          },
        });
      }
    } catch (error) {
      if (error instanceof Error) {
        console.warn(`Skipping ${file.name}: ${error.message}`);
      }
      continue;
    }
  }
  // Sort matches by similarity (highest first)
  matches.sort((a, b) => b.similarity - a.similarity);
  console.log('Final matches:', matches);
  return {
    matches,
  };
});
</file>

<file path="src/use-cases/health/index.test.ts">
import { describe, it, expect } from 'vitest';
import { getHealthCheck } from './index';
describe('getHealthCheck', () => {
  it('should return a valid health check response', async () => {
    const result = await getHealthCheck();
    expect(result.success).toBe(true);
    if (result.success) {
      expect(result.data.status).toBe('ok');
      expect(new Date(result.data.timestamp)).toBeInstanceOf(Date);
    }
  });
});
</file>

<file path="src/use-cases/health/index.ts">
import { composable } from 'composable-functions';
export const getHealthCheck = composable(
  () =>
    ({
      status: 'ok',
      timestamp: new Date().toISOString(),
    }) as const,
);
</file>

<file path="src/app.ts">
import express from 'express';
import healthRoutes from './routes/health';
import faceRecognitionRouter from './routes/face-recognition';
const app = express();
app.use(express.json());
app.use('/health', healthRoutes);
app.use('/face-recognition', faceRecognitionRouter);
export default app;
</file>

<file path="src/index.ts">
import app from './app';
import { config } from 'dotenv';
config();
const port = process.env.PORT || 3000;
app.listen(port, () => {
  console.log(`Server is running on port ${port}`);
});
</file>

<file path=".eslintrc.json">
{
  "env": {
    "node": true,
    "es2022": true
  },
  "extends": [
    "eslint:recommended",
    "plugin:@typescript-eslint/recommended",
    "plugin:prettier/recommended"
  ],
  "parser": "@typescript-eslint/parser",
  "parserOptions": {
    "ecmaVersion": "latest",
    "sourceType": "module"
  },
  "plugins": ["@typescript-eslint", "prettier"],
  "rules": {
    "prettier/prettier": "error",
    "@typescript-eslint/explicit-function-return-type": "error",
    "@typescript-eslint/no-unused-vars": ["error", { "argsIgnorePattern": "^_" }],
    "@typescript-eslint/no-explicit-any": "error"
  }
}
</file>

<file path=".gitignore">
# Dependencies
node_modules/
.pnp/
.pnp.js

# Build
dist/
build/

# Environment
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# Logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# IDE
.idea/
.vscode/
*.swp
*.swo

# Testing
coverage/

# OS
.DS_Store
Thumbs.db 

# Local research for cursor-tools
research/

# Storage
storage/faces/*
!storage/faces/.gitkeep
storage/gallery/*
!storage/gallery/.gitkeep

# Models
models/*
!models/.gitkeep
</file>

<file path=".prettierrc">
{
  "semi": true,
  "trailingComma": "all",
  "singleQuote": true,
  "printWidth": 80,
  "tabWidth": 2
}
</file>

<file path="jest.config.js">
export default {
  preset: 'ts-jest',
  testEnvironment: 'node',
  extensionsToTreatAsEsm: ['.ts'],
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/src/$1',
    '^(\\.{1,2}/.*)\\.js$': '$1',
  },
  testMatch: ['**/*.integration.test.ts'],
  transform: {
    '^.+\\.tsx?$': [
      'ts-jest',
      {
        useESM: true,
      },
    ],
  },
  moduleDirectories: ['node_modules', 'src'],
};
</file>

<file path="package.json">
{
  "name": "face-recognition-api",
  "version": "1.0.0",
  "description": "A RESTful API for face recognition",
  "type": "module",
  "main": "dist/index.js",
  "scripts": {
    "dev": "tsx watch src/index.ts",
    "build": "tsc",
    "start": "node dist/index.js",
    "test": "npm run test:unit && npm run test:integration",
    "test:unit": "vitest run",
    "test:watch": "vitest watch",
    "test:integration": "jest --config jest.config.js",
    "format": "prettier --write \"src/**/*.ts\"",
    "lint": "eslint \"src/**/*.ts\" --fix",
    "prepare": "husky"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "canvas": "^3.1.0",
    "composable-functions": "^4.5.0",
    "dotenv": "^16.4.1",
    "express": "^4.18.2",
    "face-api.js": "^0.22.2",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/express": "^4.17.21",
    "@types/jest": "^29.5.11",
    "@types/node": "^20.11.16",
    "@types/supertest": "^6.0.2",
    "@typescript-eslint/eslint-plugin": "^6.20.0",
    "@typescript-eslint/parser": "^6.20.0",
    "eslint": "^8.56.0",
    "eslint-config-prettier": "^9.1.0",
    "eslint-plugin-prettier": "^5.1.3",
    "husky": "^9.0.7",
    "jest": "^29.7.0",
    "prettier": "^3.2.4",
    "supertest": "^6.3.4",
    "ts-jest": "^29.1.2",
    "tsx": "^4.7.0",
    "typescript": "^5.3.3",
    "vitest": "^1.2.2"
  }
}
</file>

<file path="README.md">
# Face Recognition API

A REST API for face recognition in images using face-api.js.

## Features

- Face detection and recognition using face-api.js
- Search for matching faces in image albums
- Type-safe API with Zod validation
- Composable and testable architecture
- Integration and unit tests

## Prerequisites

- Node.js 18 or higher
- npm or yarn

## Setup

1. Clone the repository:

```bash
git clone https://github.com/yourusername/face-recognition-api.git
cd face-recognition-api
```

2. Install dependencies:

```bash
npm install
```

3. Run the setup script to download face-api.js models and create necessary directories:

```bash
chmod +x scripts/setup.sh
./scripts/setup.sh
```

4. Create a `.env` file:

```bash
cp .env.sample .env
```

5. Add your face images:

- Put face images to search for in `storage/faces/`
- Create albums in `storage/gallery/`
- Add pictures to search through in `storage/gallery/<album-name>/`

## Development

Start the development server:

```bash
npm run dev
```

Run tests:

```bash
npm test
```

Run linter:

```bash
npm run lint
```

Format code:

```bash
npm run format
```

## API Endpoints

### POST /face-recognition/match

Search for matching faces in an album.

**Request Body:**

```json
{
  "albumName": "my-album",
  "facePath": "person.jpg"
}
```

**Response:**

```json
{
  "matches": [
    {
      "imagePath": "storage/gallery/my-album/photo1.jpg",
      "similarity": 0.92,
      "boundingBox": {
        "x": 100,
        "y": 50,
        "width": 200,
        "height": 200
      }
    }
  ]
}
```

## Project Structure

- `src/` - Source code
  - `types/` - TypeScript types and Zod schemas
  - `routes/` - Express route handlers
  - `use-cases/` - Business logic
  - `middleware/` - Express middleware
- `storage/` - Image storage
  - `faces/` - Face images to search for
  - `gallery/` - Albums of images to search through
- `models/` - face-api.js model files
- `scripts/` - Setup and utility scripts

## Contributing

1. Create a feature branch
2. Make your changes
3. Run tests and linting
4. Create a pull request

## License

MIT
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "Bundler",
    "esModuleInterop": true,
    "strict": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "outDir": "dist",
    "rootDir": "src",
    "baseUrl": "src",
    "paths": {
      "@/*": ["*"]
    }
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "**/*.test.ts", "**/*.spec.ts"]
}
</file>

<file path="vitest.config.ts">
import { defineConfig } from 'vitest/config';
import path from 'path';
export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    exclude: ['**/*.integration.test.ts', 'node_modules'],
  },
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src'),
    },
  },
});
</file>

</files>
